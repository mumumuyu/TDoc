# mysql

## mysql逻辑结构与存储结构

存储：

Row行=>Page页（Block块）=> Extent区=>Segment段=>Tablespace表空间

表空间

- 独立表空间，每张表都会生成独立的文件方式来进行存储，如.frm描述文件+.ibd，包括单独一个表的数据内容以及索引内容
- 共享表空间：InnoDB所有数据存储在一个单独的表空间里，该表空间由很多文件组成，一个表可以跨多个文件存在，大小只有自身限制，最大64TB，包含索引等其他相关数据

InnoDB将数据保存在表空间中，InnoDB存储引擎逻辑结构的最高层。本质是一个或多个磁盘文件组成的虚拟文件系统，当然其不止存储表和索引，还保存了回滚段，双写缓冲区

表空间类型

- 系统表空间
- 表文件表空间
- 通用表空间
- undo表空间
- 临时表空间

段

表空间由各个段组成，常见的段：数据段，索引段，回滚段

区

由连续的页组成，每个页大小1MB，为保证连续性，InnoDB会每次从磁盘申请4~5个区，默认存储引擎每页大小16KB,一个区有有64个连续页

...

## mysql如何实现事务

已提交读与可重复读区别：

giao，记混了😭

已提交读就是只读取提交后的数据，容易造成幻读 数据条数不一致，并且不能保证每次读到的同一数据一致

可重复读就是提交前每次只读取第一次读到的信息，所以解决了不可重复读的问题，但当其他事务已经提交并改变了数据条数，两次读取数据(不含where的话)的条数不同所以会造成幻读



实现事务要达到最重要点是可靠和并发处理

可靠：数据库执行crud与crash时需要保证操作前后一致，undo/redo log存在意义

并发处理： 在多个请求并发进行时，不同事物之间进行隔离，用到日志文件，mysql锁以及MVCC

#### mysql锁：

运用读写锁，读锁（共享锁），写锁（排他锁）

只有多个读锁之间可以并行操作

#### MVCC

多版本并发控制MultiVersion Concurrency Control

InnoDB的MVCC是通过每行数据纪律后两个隐藏的列来实现的（一个创建时间，一个过期时间）(不是真实时间，而是版本号)通过数据的多版本来做到不加锁进而读写并行

mysql运用undo log 和 read view记录某行数据多版本数据，其中undo log记录某行数据多版本数据，read view可用于判断当前版本数据可见性，读写锁在提交读级别下的应用

![img](https://img-blog.csdnimg.cn/img_convert/0683aa45f0bea9f4e79bfea9fc589ee8.png)

事物的原子性通过undo log实现，持久性通过redo log实现

说到事务都知道，经典的ACID，原子性，永久性，隔离性，一致性

原子性和持久性是为了给数据提供可靠的保障，死机了也可以恢复，出错了也可以回滚。

隔离性是为了保证并发的情况下，事务不会被相互影响到，可靠和数据性能不可兼得，当可靠性高了后并发性能就低了，而并发性能上去后，可靠性又低了。

- 原子性：说白了就是事务不可以只执行一部分，必须全部执行，要么全部不执行

  有些时候可能我们的事务执行到一般会出现异常或错误，需要rollback到事务执行前，Mysql通过undo log实现，undo log顾名思义，就是do了啥undo啥嘛，比如执行了插入操作，那undo回滚时进行删除这条数据的操作。

- 持久性：要保证事务提交后就永久保存在磁盘中

  mysql因为数据存储在磁盘中，每次读取需要磁盘IO，但磁盘IO很有限，非常耗资源，所以用到了缓存池(数据页的映射)，执行读时，先去buffer pool中读，未命中则从磁盘中找出来放入缓存池中，写也是，先写入到缓存池，然后等到定时同步的时候一次性写入到磁盘中。

  有时候数据库会出现crash崩溃，那如何保证事务一旦提交的改变是永久的呢

  在执行事务时，事务开始=>进行Insert将数据插入到Buffer pool中=>记录redo log buffer=>同步到磁盘中redo log =>提交事务		而对于数据，后台线程会采用轮询的方式进行同步(NIO多路复用咯)

  重点：**必须先写入日志，后写入数据库**

  ![img](https://img-blog.csdnimg.cn/img_convert/253bf83c88304885a4c79e1496dc2e35.png)

- 隔离性：最为复杂，分为四个隔离级别。

  低到高有：readUncommited，readCommited，repeatableread，serializable

  readUncommited未提交读

  在未提交读的隔离级别下，事务中的修改即使还没提交，对其他事务也是可见的，这样就很容易造成读脏数据的现象。因为读请求是不会添加任何锁的，所以假如写操作在读的过程中修改数据，就会出现数据不一致的情况，但是这种隔离级别读操作不能排斥写请求，也就提高了并发处理的性能，从而做到读写并行。

  ![img](https://img-blog.csdnimg.cn/img_convert/21395fd815b9bc055c2b193c1787ea55.png)

  　　readcommited：在提交读的隔离级别下，一个事务的修改在他提交之前对其他事务都是不可兼得。其他事务只可以读到已提交的修改数据变化，在很多场景下这种逻辑是可以接受的。InnoDB在readcommited中使用了MVCC机制，或者换句话就是读写分离机制。但是在这个级别下会产生不可重复读（在一个事务中多次读取的结果不一样）的问题，为什么会产生这种问题呢？这个和MVCC的机制有关系，在这个隔离级别下每次进行select操作时都会在其生成一个新的版本号，这样每次select读到的不是一个副本而是不同的副本。这样在每次select之间假使有其他事物更新我们读取的数据并提交后，就出现了不可重复读的现象。

  　　repeatableread（MySQL默认隔离级别）：在一个事务中多次读取的数据结果是一样的，这种级别可以有效的避免脏读及不可重复读等查询问题，MySQL有两种机制都可以达到这种隔离级别分别是用读写锁：

  ![img](https://img-blog.csdnimg.cn/img_convert/67514162936a1fcd45f6197025fa69a4.png)

  　　这样为什么能够实现重复读呢？是因为只要没释放读锁，在次读的时候都可以读到第一次读到的数据，这样虽然实现简单，但是却无法实现读写并行。另外一种是MVCC实现：

  ![img](https://img-blog.csdnimg.cn/img_convert/a862317077b558a217502cdd35ee1f7c.png)

  　　这样为什么可以重复读呢？是因为多次读取到的数据只生成了一个版本，这样自然也就可以读到相同的数据，这样可以实现读写并行，但是实现起来复杂度极高。

  　　serializable：这种序列化读级别下理解起来最简单实现起来也最简单，但是除了不会造成数据不一致的问题，就没有其他任何的优点了。

  ![img](https://img-blog.csdnimg.cn/img_convert/7b69de245270949b5d4155990008a9e7.png)

  　　***一致性***的实现：对于一个数据库来说，总是从一种状态转移到另外一种状态：比如我要从一个银行卡转出400块钱到另外一个理财的账户中

  　　假如执行完 update bank set balance = balance - 400;之后数据库发生了异常了，银行肯定不允许客户钱平白无故的减少，就可以回滚到最初的状态。又或者事务提交之后，缓冲池还没同步到磁盘的时候死机了了，这也是不能接受的，应该在重启的时候恢复并持久化。假如有并发事务请求的时候也应该做好事务之间的可见性问题，避免造成脏读，不可重复读，幻读等。在涉及并发的情况下往往在性能和一致性之间做平衡，做一定的取舍，所以从这个角度看，隔离性也是对一致性的一种逆向削弱。

  　最后，总的说来实现事务采取了哪些技术以及思想？原子性使用 undo log ，从而达到回滚；持久性：用 redo log，从而达到故障后恢复；隔离性使用锁以及MVCC,运用的优化思想有读写分离，读读并行，读写并行；一致性：通过回滚，以及恢复，和在并发环境下的隔离做到一致性。

## MySQL数据库类型

数值类型
有包括 TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示 1 字节、2 字节、3 字节、4 字节、8 字节的整数类型。

1）任何整数类型都可以加上 UNSIGNED 属性，表示无符号整数。

2）任何整数类型都可以指定长度，但它不会限制数据的合法长度，仅仅限制了显示长度。

还有包括 FLOAT、DOUBLE、DECIMAL 在内的小数类型。

字符串类型
包括 VARCHAR、CHAR、TEXT、BLOB。

注意：VARCHAR(n) 和 CHAR(n) 中的 n 并不代表字节个数，而是代表字符的个数。

日期和时间类型
常用于表示日期和时间类型为 DATETIME、DATE 和 TIMESTAMP。

尽量使用 TIMESTAMP，空间效率高于 DATETIME。

ref MySQL 数据类型

#### CHAR 和 VARCHAR 区别

1）首先可以明确的是 CHAR 是定长的，而 VARCHAR 是可以变长。

CHAR 会根据声明的字符串长度分配空间，并会使用空格对字符串右边进行尾部填充。所以在检索 CHAR 类型数据时尾部空格会被删除，如保存的是字符串 'char '，但最后查询到的是 'char'。又因为长度固定，所以存储效率高于 VARCHAR 类型。

VARCHAR 在 MySQL 5.0 之后长度支持到 65535 字节，但会在数据开头使用额外 1~2 个字节存储字符串长度（列长度小于 255 字节时使用 1 字节表示，否则 2 字节），在结尾使用 1 字节表示字符串结束。

2）再者，在存储方式上，CHAR 对英文字符（ASCII）占用 1 字节，对一个汉字使用用 2 字节。而 VARCHAR 对每个字符均使用 2 字节。

虽然 VARCHAR 是根据字符串长度分配存储空间的，但在内存中依旧使用声明长度进行排序等作业，故在使用时仍需综合考量字段长度。

#### CHAR 和 VARCHAR 如何选择？

1）对于经常变更的数据来说，CHAR 比 VARCHAR更好，因为 CHAR 不容易产生碎片。

2）对于非常短的列或固定长度的数据（如 MD5），CHAR 比 VARCHAR 在存储空间上更有效率。

4）使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。

4）尽量避免使用 TEXT/BLOB 类型，查询时会使用临时表，导致严重的性能开销。

#### CHAR，VARCHAR 和 Text 的区别

1）长度区别

Char 范围是 0～255。

Varchar 最长是 64k（注意这里的 64k 是整个 row 的长度，要考虑到其它的 column，还有如果存在 not null 的时候也会占用一位，对不同的字符集，有效长度还不一样，比如 utf-8 的，最多 21845，还要除去别的column），但 Varchar 在一般情况下存储都够用了。

如果遇到了大文本，考虑使用 Text，最大能到 4G（其中 TEXT 长度 65,535 bytes，约 64kb；MEDIUMTEXT 长度 16,777,215 bytes，约 16 Mb；而 LONGTEXT 长度 4,294,967,295 bytes，约 4Gb）。

2）效率区别

效率来说基本是 Char > Varchar > Text，但是如果使用的是 Innodb 引擎的话，推荐使用 Varchar 代替 Char。

3）默认值区别

Char 和 Varchar 支持设置默认值，而 Text 不能指定默认值。

## 数据库存储结构

存储结构

### 1、什么是 InnoDB 的页、区、段？

页（Page）
首先，InnoDB 将物理磁盘划分为页（page），每页的大小默认为 16 KB，页是最小的存储单位。页根据上层应用的需要，如索引、日志等，分为很多的格式。我们主要说数据页，也就是存储实际数据的页。

区（Extent）
如果只有页这一个层次的话，页的个数是非常多的，存储空间的分配和回收都会很麻烦，因为要维护这么多的页的状态是非常麻烦的。

所以，InnoDB 又引入了区（Extent) 的概念。一个区默认是 64 个连续的页组成的，也就是 1MB。通过 Extent 对存储空间的分配和回收就比较容易了。

段（Segment）
为什么要引入段呢，这要从索引说起。我们都知道索引的目的是为了加快查找速度，是一种典型的用空间换时间的方法。

B+ 树的叶子节点存放的是我们的具体数据，非叶子结点是索引页。所以 B+ 树将数据分为了两部分，叶子节点部分和非叶子节点部分，也就我们要介绍的段 Segment，也就是说 InnoBD 中每一个索引都会创建两个 Segment 来存放对应的两部分数据。

Segment 是一种逻辑上的组织，其层次结构从上到下一次为 Segment、Extent、Page。

### 2、页由哪些数据组成？

首先看数据页的基本格式，如下图：

![img](https://img-blog.csdnimg.cn/20201119104126815.png)


File Header
用于描述数据页的外部信息，比如属于哪一个表空间、前后页的页号等。

Page Header
用来描述数据页中的具体信息，比如存在多少条纪录，第一条纪录的位置等。

infimum 和 supremum 纪录
infimum 和 supremum 是系统生成的纪录，分别为最小和最大纪录值，infimum 的下一条是用户纪录中键值最小的纪录，supremum 的上一条是用户纪录中键值最大的纪录，通过 next_record 字段来相连。

User Records
用户纪录，也就是数据库表中对应的数据，这里我们说常用的 Compact 格式。



InnoDB 除了我们插入的数据外，还有一些隐藏列，transaction_id（事务ID）、roll_pointer（回滚指针）是一定添加的。

row_id 则不一定，根据以下策略生成：优先使用用户建表时指定的主键，若用户没有指定主键，则使用unique键。若unique键都没有，则系统自动生成row_id，为隐藏列。

Free Space
页中目前空闲的存储，可以插入纪录。

Page Dictionary
类似于字典的目录结构，根据主键大小，每隔 4-8 个纪录设置一个槽，用来纪录其位置，当根据主键查找数据时，首先一步到位找到数据所在的槽，然后在槽中线性搜素。这种方法比从前到后遍历页的链表的效率更快。

Page Tailer
File Header存储刷盘前内存的校验和，Page Tailer储存刷盘后的校验和。当刷盘的时候，出现异常，Page Tailer和File Header中的校验和不一致，则说明出现刷盘错误。

### 3、页中插入记录的过程？

1）如果 Free Space 的空间足够的话，直接分配空间来添加纪录，并将插入前最后一条纪录的 next_record 指向当前插入的纪录，将当前插入纪录的 next_record 指向 supremum 纪录。

2）如果 Free Space的 空间不够的话，则首先将之前删除造成的碎片重新整理之后，按照上述步骤插入纪录。

3）如果当前页空间整理碎片之后仍然不足的话，则重新申请一个页，将页初始化之后，按照上述步骤插入纪录

###  数据库设计

#### 1、什么是三大范式？

第一范式（1NF）：字段（或属性）是不可分割的最小单元，即不会有重复的列，体现原子性

第二范式（2NF）：满足 1NF 前提下，存在一个候选码，非主属性全部依赖该候选码，即存在主键，体现唯一性，专业术语则是消除部分函数依赖

第三范式（3NF）：满足 2NF 前提下，非主属性必须互不依赖，消除传递依赖

ref：如何理解关系型数据库的常见设计范式？

除了三大范式外，还有BC范式和第四范式，但其规范过于严苛，在生产中往往使用不到。

#### 2、什么是范式和反范式，以及各自优缺点？

范式是符合某一种级别的关系模式的集合。构造数据库必须遵循一定的规则。在关系数据库中，这种规则就是范式。

名称	优点	缺点
范式	范式化的表减少了数据冗余，数据表更新操作快、占用存储空间少。	查询时通常需要多表关联查询，更难进行索引优化
反范式	反范式的过程就是通过冗余数据来提高查询性能，可以减少表关联和更好进行索引优化	存在大量冗余数据，并且数据的维护成本更高
所以在平时工作中，我们通常是将范式和反范式相互结合使用。

## **基本用法**

```sql
select xxx,count(distinct(xxx)) xxx,xxx from xxx x,xxxx xx where (xxx) or (xxx) group by xxx order by xxx (DESC) having xxx
```

### **逻辑判断**

```sql
(CASE
    when age<20 then '20岁以下'
    when age between 20 and 24 then '20-24岁'
    when age>=25 then '25岁及以上'
    else '其他' end ) as age_cut
```

### **日期**

```sql
SELECT 1 '月份', count(id) '个数'
from `order`
where month(create_time) = '1' and year(create_time) = '2022'
union all
SELECT 2 '月份', count(id) '个数'
from `order`
where month(create_time) = '2' and year(create_time) = '2022'
union all
SELECT 3 '月份', count(id) '个数'
from `order`
where month(create_time) = '3' and year(create_time) = '2022'
```

### **切分字符**

```sql
substring_index(profile,',',-1) //获取，号分开的某个字段的最后一部分
								//1，就是获取第一部分，2就是获取第一部分加第二部分
```

### **窗口函数**

join

```sql
select a.device_id,a.university,a.gpa
from user_profile a join 
(
    select university,min(gpa) gpa
    from user_profile 
    group by university
) as b on a.university = b.university and a.gpa = b.gpa
order by university
```

##### Union和Union All

Union在整理的过程中会将一些重复的选项筛选，并且针对所产生的结果进行排列顺序之后运算。所删除的记录会再次返回到结果当中。

Union all操作过程中会针对两个结果直接合并之后就会返回。

##### **Date和DateTime**

Date

显示格式：YYYY-MM-DD

DateTime

显示格式：YYYY-MM-DD HH:mm:ss

复合索引最左原则

- 最左优先就是说组合索引的第一个字段必须出现在查询组句中，这个索引才会被用到。只要组合索引最左边第一个字段出现在Where中，那么不管后面的字段出现与否或者出现顺序如何，MySQL引擎都会自动调用索引来优化查询效率。
- 根据最左匹配原则可以知道B-Tree建立索引的过程，比如假设有一个3列索引(col1,col2,col3),那么MySQL只会会建立三个索引(col1),(col1,col2),(col1,col2,col3)。

MYSQL中处理插入过程主键或唯一重复值的解决办法：

1.IGNORE:有则忽略，无则插入

2.REPLACE：有则删除再插入，无则插入

3.ON DUPLIACATE KEY UPDATE:有则更新，无则插入

##### 一次性插入百万级数量示例

set global log_bin_trust_function_creators=TRUE;

```sql
DELIMITER $$
-- 写函数之前必须要写，标志
CREATE FUNCTION mock_data2 ()
RETURNS INT
BEGIN
DECLARE num INT DEFAULT 10000;
DECLARE i INT DEFAULT 0;
WHILE i<num DO
INSERT INTO `app_user`(`name`,`email`,`phone`,`gender`)VALUES(CONCAT('用户',i),'1017276522@qq.com','123456789',FLOOR(RAND()*2));
SET i=i+1;
END WHILE;
RETURN i;
END;
SELECT mock_data2() -- 执行此函数 生成一万条数据
```

## 数据库基本知识及mysql

##### 左连接 右连接 内连接

表1 id 123  表2 id 124

左连接 ：以左表为基础关联右表	123

右连接 ：以右表为基础关联左表	124

内连接：关联两表里都有的字段 	12

### 数据连接池

j2ee的server启动后会建立一定数量的池连接，并维持这个数目。当Browser需要连接后会返回一个未使用的池连接并进行标记。若没有空闲连接就会创建一定数量的连接（由配置参数决定）当池子连接使用完毕就会标记为空闲。

### 继承映射

1.按继承结构，多少个子类都一张

- 单表策略，无需表连接，查询快，适合多态查询

2.子类一张，公共信息一张，特有信息一张

- 多表查询，需要连接，数据紧凑

3.具体类一张，多少个子类多少张表

### 数据库的优化

- 为了查询更快，表中字段宽度尽可能小，查询时，需要什么数据查什么数据，不要直接*
- 使用连接(join)代替子查询
- 使用union来代替手动创建临时表，用Union将多个select语句连接就可以，不过select的字段数要相同
- 当数据特别多时，可以通过横向分表（分列）或者纵向（分数据量）

### left / right join

left join : 以左表位基准，将左表数据全部表示出来，而右表显示符合条件的记录

### 主从复制

主服务器对数据库修改记录二进制日志，从服务器通过二进制日志执行自动更新

### ACID

- 原子性：事务是一个不可分割的工作单位，事务要么都完成，要么都不完成
- 一致性：事务前后数据的完整性必须保持一致
- 隔离性：多个用户并发访问数据库时，一个用户的事务不可以被其它用户干扰，不同事物之间数据要相互隔离
- 持久性：一个事务一旦提交就是永久性改变。

### 范式

1. 第一范式

   列原子性，不可以再分成别的列，一个表要有主键且其余列必须完全依赖主键

2. 2NF

   非主属性间不可存在依赖，且非主键必须直接依赖于主键

3. 3NF

### 锁

- 悲观锁：很悲观，每次拿数据都觉得别人会修改，所以拿数据时候会给数据上锁别人想拿就会被Block直到拿到锁。可以避免发生并发冲突，如synchronized
- 乐观锁：很乐观，每次拿数据都不上锁。适用于读多写少，可以提高吞吐量。如无并发冲突，只在提交时检查数据完整性
  - 数据版本记录机制：（数据版本：表字段加一个version。读取时将version一块取出。每更新一次，version+1）当我们提交更新时，将当前数据库表version信息与第一次取时进行对比，一致就更新，否则认为过期
  - 时间戳(timestamp)，增加一个字段（名字无所谓，类型一定要是timestamp），与version类似，在提交更新时讲当前表timestamp与取到时进行对比，一致就更新，否则版本冲突

### 隔离级别

```sql
-- REPEATABLE-READ
show variables like "%iso%"

set session TRANSACTION ISOLATION LEVEL REPEATABLE READ
```

| 隔离级别                     | 脏读（Dirty Read） | 不可重复读（NonRepeatable Read） | 幻读（Phantom Read） |
| ---------------------------- | ------------------ | -------------------------------- | -------------------- |
| 未提交读（Read uncommitted） | 可能               | 可能                             | 可能                 |
| 已提交读（Read committed）   | 不可能             | 可能                             | 可能                 |
| 可重复读（Repeatable read）  | 不可能             | 不可能                           | 可能                 |
| 可串行化（Serializable ）    | 不可能             | 不可能                           | 不可能               |

- 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据。

- 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)。

- 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读。

- 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。

关于脏读，不可重复读，幻读

- 脏读：一个事务读取到了未提交的数据，而前面那个事务回滚了，就出现了脏读
- 不可重复读：同一事务，同一个select得到不同结果(数据变化)
- 幻读：用户读取一个范围数据时插入数据，用户再次读取同一个范围时多出一条“幻影”数据(行数变化)

### 索引

B+树，数据仅存储于叶子节点，且从左到右可以串联便于范围查询，导致索引符合最左原则

#### 从应用上可以划分为一下几类：

普通索引：MySQL 中的基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值，纯粹为了提高查询效率。通过 ALTER TABLE table_name ADD INDEX index_name (column) 创建；

唯一索引：索引列中的值必须是唯一的，但是允许为空值。通过 ALTER TABLE table_name ADD UNIQUE index_name (column) 创建；

主键索引：特殊的唯一索引，也成聚簇索引，不允许有空值，并由数据库帮我们自动创建；

组合索引：组合表中多个字段创建的索引，遵守最左前缀匹配规则；

全文索引：只有在 MyISAM 引擎上才能使用，同时只支持 CHAR、VARCHAR、TEXT 类型字段上使用。

#### 索引设计原则

选择唯一性索引；
唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。

为常作为查询条件的字段建立索引；
如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。

为经常需要排序、分组和联合操作的字段建立索引；
经常需要 ORDER BY、GROUP BY、DISTINCT 和 UNION 等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。

限制索引的数目；
每个索引都需要占⽤用磁盘空间，索引越多，需要的磁盘空间就越大，修改表时，对索引的重构和更新很麻烦。

小表不建议索引（如数量级在百万以内）；
由于数据较小，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果。

尽量使用数据量少的索引；
如果索引的值很长，那么查询的速度会受到影响。此时尽量使用前缀索引。

删除不再使用或者很少使用的索引。

### 引擎

InnoDB是聚集索引，支持事务，行级锁

面向在线事务处理

MyISAM非聚集，不支持事务，支持行级锁

### MyISAM和InnoDB的区别

①InnoDB支持事务与外键和行级锁,MyISAM不支持(最主要的差别)

②MyISAM读性能要优于InnoDB,除了针对索引的update操作,MyISAM的写性能可能低于InnoDB,其他操作MyISAM的写性能也是优于InnoDB的,而且可以通过分库分表来提高MyISAM写操作的速度

③MyISAM的索引和数据是分开的,而且索引是压缩的,而InnoDB的索引和数据是紧密捆绑的,没有使用压缩,所以InnoDB的体积比MyISAM庞大

MyISAM引擎索引结构的叶子节点的数据域，存放的并不是实际的数据记录，而是数据记录的地址。索引文件与数据文件分离，这样的索引称为“非聚簇索引”。其检索算法：先按照B+Tree的检索算法检索，找到指定关键字，则取出对应数据域的值，作为地址取出数据记录。

InnoDB引擎索引结构的叶子节点的数据域，存放的就是实际的数据记录。这样的索引被称为“聚簇索引”，一个表只能有一个聚簇索引。

④InnoDB 中不保存表的具体行数，也就是说，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count(*)语句包含 where条件时，两种表的操作是一样的。

⑤DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除。

⑥InnoDB表的行锁也不是绝对的，假如在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表，例如update table set num=1 where name like “%aaa%”

在where条件没有主键时,InnoDB照样会锁全表

 

选择哪种搜索引擎,应视具体应用而定

①如果是读多写少的项目,可以考虑使用MyISAM,MYISAM索引和数据是分开的，而且其索引是压缩的，可以更好地利用内存。所以它的查询性能明显优于INNODB。压缩后的索引也能节约一些磁盘空间。MYISAM拥有全文索引的功能，这可以极大地优化LIKE查询的效率。

②如果你的应用程序一定要使用事务，毫无疑问你要选择INNODB引擎

③如果是用MyISAM的话，merge引擎可以大大加快应用部门的开发速度，他们只要对这个merge表做一些select count(*)操作，非常适合大项目总量约几亿的rows某一类型(如日志，调查统计)的业务表。

### 切分

垂直切分：表按模块划分到不同数据库，（列）表数据拆分到不同表

水平切分：单表大数据量，行数据拆分到不同表

### JDBC事务处理

connection调用setAutoCommit设置是否手动提交事务

完成事务commit();否则rollback()

savapoint，可以设置保存点让事务回滚到指定保存点

关于事务，在面试中被问到的概率是很高的，可以问的问题也是很多的。首先需要知道的是，只有存在并发数据访问时才需要事务。当多个事务访问同一数据时，可能会存在5类问题，包括3类数据读取问题（脏读、不可重复读和幻读）和2类数据更新问题（第1类丢失更新和第2类丢失更新）。

事物的ACID:

Atomic：要么全做，要不全不做

Consistent:结束前后系统状态一致

Isolated:事务彼此无法看到对方状态

Durable:改动会持久化

### Mysql如何实现事务？



### 性能问题

statement And PrepareStatement

prepareStatement:可以防止sql注入，增加安全性，自动增加''，可以带参数，数据库可以缓存编译优化后的sql，批处理时有明显的性能优势。

JDBC的反射及作用

通过反射com.mysql.jdbc.Driver类，实例化该类的时候会执行该类内部的静态代码块，该代码块会在Java实现的DriverManager类中注册自己,DriverManager管理所有已经注册的驱动类，当调用DriverManager.geConnection方法时会遍历这些驱动类，并尝试去连接数据库，只要有一个能连接成功，就返回Connection对象，否则则报异常。

为什么树查询快?

从根节点开始，沿路径查找，中序遍历得到结果是递增排序的结点序列,二叉树一般为二叉查找树，当先后插入完全有序下退化为单只树。树的查询效率与高度相关，为例高度尽量低，左右子树尽量平衡，出来了平衡二叉树，查询复杂度在O（log N），但是删除时必须检查从删除节点到根节点路径上所有平衡因子，代价为O(2log N),那为了 提升插入与删除效率，可以牺牲一点平衡度，不需要那么严格的平衡，所以出来了红黑树，红黑树与完全平衡二叉树差不多查询性能，但是插入最多两次，删除最多三次旋转，代价优于完全平衡。

但是红黑树也可能出现在数据量过大情况下也可能出现，层数过多情况，所以引申出B-树，B+树

### 回表

例如(当查询列不存在于索引中)使用非主键索引的查询，在搜索完非主键索引树后得到主键值，还需要到主键索引树再去搜索一次，所以虽然用了索引，但底层进行了两次索引查询，这就是回表。

### 覆盖索引

使用索引覆盖需要寻找的值

假设有个表

| 表   | info     |
| ---- | -------- |
| 主键 | id       |
| 名称 | name     |
| 值   | value    |
| 别名 | realname |

对于info表，现在有（name,value）联合索引

需要查询realname，1.不查询realname 2.将realname加入一个索引，这就是索引覆盖

### delete,drop,truncate区别

delete用于删除表部分或所有数据,delete(DML Data Manipulation Language数据操纵语言)在InnoDB中只是给数据打上删除标记，可以通过将自动提交设置为set autocommit = 0，然后进行rollback看，数据还在，证明不是真的物理删除。

truncate与delete类似 truncate from student where id = 5

不同点是truncate不支持条件表达式，只能删除所有行数据，它是DDL语句(Data Definition Language)数据定义语言

drop是删除整张表，含数据，字段，索引，truncate和delete只删除行数据

执行速度drop>truncate>delete

### MVCC

Multi Version Concurrency Control，多版本并发控制

乐观锁的体现，最大优势：读不加锁，读写不冲突

InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的，分别保存这条行的**创建时间**和**行的删除时间**。这里的时间并不是实际的时间值，而是**系统版本号（事务的ID）**。事务开始时刻的系统版本号会作为事务的ID，每次执行一个新事务，系统版本号就会自动递增。随之引出了**当前读**和**快照读**。

**当前读**：select xxx lock in share mode(共享锁)，读取的是记录的最新版本，读取时保证其他事务不修改当前记录，会对读取记录进行加锁

**快照读**：前提：隔离级别不是串行级别，串行级别下快照读会退化为当前读，快照读避免加锁，所以可能不一定是最新版本如select xxx，不加锁的简单select都属于快照读

MVCC只在隔离级别为可重复读和提交读级别下工作

## MVCC的实现原理 

 每一行记录有三个隐藏键，分别为DATA_TRX_ID、DATA_ROLL_PTR、DB_ROW_ID，其中： 

 **DATA_TRX_ID**
 记录最近更新这条行记录的事务 ID，大小为 6 个字节 

 **DATA_ROLL_PTR**
 表示指向该行回滚段（rollback segment）的指针，大小为 7 个字节，InnoDB 便是通过这个指针找到之前版本的[数据]()。该行记录上所有旧版本，在 undo 中都通过[链表]()的形式组织。 

 **DB_ROW_ID**
 行标识（隐藏单调自增 ID），大小为 6 字节，如果表没有主键，InnoDB 会自动生成一个隐藏主键，即此列。 

 为了让大家更直观地理解 MVCC 的实现原理，这里举一个“事务对某行记录更新的过程”的案例来讲解 MVCC 中多版本的实现。 

 假设 F1～F6 是表中字段的名字，1～6 是其对应的[数据]()。后面三个隐含字段分别对应该行的隐含ID、事务号和回滚指针，如下图所示。 

![img](https://uploadfiles.nowcoder.com/images/20210804/821556076_1628054801124/9865DE751FD52158E3DDD815F6077BD8)

 具体的更新过程，简单描述如下。 

 首先，假如这条[数据]()是刚 INSERT 的，可以认为 ID 为 1，其他两个字段为空。 

 然后，当事务 1 更改该行的[数据]()值时，会进行如下操作，如下图所示。 

​     ![img](https://uploadfiles.nowcoder.com/images/20210804/821556076_1628054809278/BD385DC6F10BEC922D9881F512286671)    

​     用排他锁锁定该行；记录 Redo log；    

 把该行修改前的值复制到 Undo log，即图中下面的行； 

 修改当前行的值，填写事务编号，使回滚指针指向 Undo log 中修改前的行。 

 接下来，与事务 1 相同，此时 Undo log 中有两行记录，并且通过回滚指针连在一起。因此，如果 Undo log 一直不删除，则会通过当前记录的回滚指针回溯到该行创建时的初始内容，所幸的是在 InnoDB 中存在 purge 线程，它会查询那些比现在最老的活动事务还早的 Undo log，并删除它们，从而保证 Undo log 文件不会无限增长，如下图所示。 

![img](https://uploadfiles.nowcoder.com/images/20210804/821556076_1628054821818/97F9C71CAEB8A53591CFD5FB4FCF9191)

 如果此时事务回滚，那么可以根据回滚指针，对[数据]()依次进行回滚并找到undo log中[数据]()行为当前事务id的一列，进行[数据]()恢复。

## 引擎

### innodb与myisam

innobo与MyISAM都采用B+Tree结构，一个节点可以存放多个子树，data都存放在叶子节点，非叶子节点存放冗余(索引)且数据可以串联，从左到右有顺序地排列，最左原则

myisam:支持表级锁，不支持事务，他有全局索引，其data与index分开存储于MYD与MYI所以是非聚集索引，其查询与增删改快于innodb，所以比较适合小型应用比如日志。

innodb：支持事务，行级锁。5.6+后有全局索引，data与index一起存放于ibd类型文件中，它推荐有主键且整数自增，在innodb表的B+结构组建时，没有主键的话他会去找有没有哪个列的元素都是唯一不重复的，没有的话就会增加一个隐藏列。这样增加了mysql的负担，磁盘IO速度比较有限，所以mysql资源很宝贵，尽量不要让mysql去做额外事。



先说说sql最小存储单元为”页“，一页有16KB

假设一个表数据8000KB(1000页)，索引80KB(10页)(为一个字段)

若无索引，需要查询1000页，而有索引只需要10页+根据索引结果搜索对应数据(由于磁盘IO速度有限，所以不用索引明显会慢很多)

**那么我们如何设置索引呢**？

一般，

最常见为**单列索引**，主键和外键以及where 条件用到的字段可以设置

而**联合索引**在B+树为复合数据结构(多属性下如name,phone时，name为有序,phone为无序，在name相等时,phone为有序)

当使用where name = ‘zhangsan’ and phone='1320xx’去查询数据的时候，会先去根据name来判断往左还是往右，在得到name相同后再比较phone，name,phone建联合索引等价于建立了phone索引

但如果where条件没有name，那引擎就不知道先查询哪个节点

如果创建三个字段的索引index(a,b,c）相当于创建三个索引：index(a),index(a,b),index(a,b,c)。用where b=?和where b=? and c=? 和where a = ? and c = ?是不能使用到索引。因为不能不用第一个字段，也不能中断。这也就是**最左前缀原则**

索引失效的情况

- 使用函数，表达式，计算，因为值改变后无法与索引中的值匹配
- 使用了范围查找，因为二叉树的查找是=
- 使用like %
- 字符串不加''
- 少用or
- is null, is not null不可使用

当一个sql十分慢的时候

```sql
-- 使用explain plan for查看sql执行计划
-- 对于大表，执行较久的部分，表的Operation尽量使用INDEX,而不是TABLE ACCESS FULL,到对应的table进行添加INDEX,原则如上
```

![image-20220822180437899](C:\Users\L\Desktop\文档\photo\image-20220822180437899.png)

最后来看

**聚簇索引为什么比非聚式索引慢呢？**

假设有一8000条记录的表，表中每条记录在磁盘上占用1000字节，如果在一个10字节长的字段上建立非 聚簇索引主键，需要二叉树节点16000个(这16000个节点中有8000个叶节点，每个页节点都指向一个数据记录)，这样数据将占用8000条 ×1000字节/8K字节=1000个页面；索引将占用16000个节点×10字节/8K字节=20个页面，共计1020个页面。

同样一张表，如果我们在对应字段上建立聚簇索引主键，由于聚簇索引的页节点就是数据节点，所以索引节点仅有8000个，占用10个页面，数据仍然占有1000个页面。

下面我们看看在执行插入操作时，非聚簇索引的主键为什么比聚簇索引主键要快。主键约束要求主键不能出现重复，那么SQL Server是怎么知道不出现重复的呢？唯一的方法就是检索。对于非聚簇索引，只需要检索20个页面中的16000个节点就知道是否有重复，因为所有主键 键值在这16000个索引节点中都包含了。但对于聚簇索引，索引节点仅仅包含了8000个中间节点，至于会不会出现重复必须检索另外1000个页数据节点 才知道，那么相当于检索10+1000=1010个页面才知道是否有重复。所以聚簇索引主键的插入速度要比非聚簇索引主键的插入速度慢很多。

让我们再来看看数据检索的效率，如果对上述两表进行检索，在使用索引的情况下(有些时候SQL Server执行计划会选择不使用索引，不过我们这里姑且假设一定使用索引)，对于聚簇索引检索，我们可能会访问10个索引页面外加1000个数据页面得 到结果(实际情况要比这个好)，而对于非聚簇索引，系统会从20个页面中找到符合条件的节点，再映射到1000个数据页面上(这也是最糟糕的情况)，比较 一下，一个访问了1010个页面而另一个访问了1020个页面，可见检索效率差异并不是很大。所以不管非聚簇索引也好还是聚簇索引也好，都适合排序，聚簇 索引仅仅比非聚簇索引快一点。

### 索引的优化

索引就是有排序的数据结构

- 单索引5个以内
- 禁止3个表以上的join
- 重复和冗余的索引不可以存在
- 字段数<=30
- 索引必须要有default值，不可为空
- verchar索引要制定其长度
- 对于行数超过500w与容量超过2G的表要进行分表

## 一些平时使用sql用法

**问题：在进行oracle数据操作时，某条语句update很久不出。**

这种只有update无法执行其他语句可以执行的其实是因为记录锁导致的，在oracle中，执行了update或者insert语句后，都会要求commit，如果不commit却强制关闭连接，oracle就会将这条提交的记录锁住。由于我的java程序中加了事务，之前debug到一半的时候我强制把工程终止了，这样就导致没有执行事务提交，所以oracle将代码中update那一条的记录锁了。可通过下面两步解决：

**1.首先查询锁定记录**

```
SELECT s.sid, s.serial# FROM v$locked_object lo, dba_objects ao, v$session s WHERE ao.object_id = lo.object_id AND lo.session_id = s.sid;
```

**2.然后删除之**

```
ALTER system KILL session 'SID,serial#'
```



**关于COUNT(1)与COUNT(*)区别**

一、count情况

1、count(1)：可以统计表中所有数据，不统计所有的列，用1代表代码行，在统计结果中包含列字段为null的数据；其实就是计算一共有多少符合条件的行。1并不是表示第一个字段，而是表示一个固定值。其实就可以想成表中有这么一个字段，这个字段就是固定值1，count(1)，就是计算一共有多少个1。

2、count(字段)：只包含列名的列，统计表中出现该字段的次数，并且不统计字段为null的情况；如果列为主键，count(列名)效率优于count，如果列不为主键，count(1)效率优于count(列名)，如果表中存在主键，count(主键列名)效率最优 ，如果表中只有一列，则count(*)效率最优，如果表有多列，且不存在主键，则count(1)效率优于c。

3、count(*)：统计所有的列，相当于行数，统计结果中会包含字段值为null的列；执行时会把星号翻译成字段的具体名字，效果也是一样的，不过多了一个翻译的动作，比固定值的方式效率稍微低一些。

二、count执行效率

列名为主键，count(列名)比count(1)快；列名不为主键，count(1)会比count(列名)快；

如果表中多个列并且没有主键，则count(1)的执行效率优于count(*)；

如果有主键，则select count(主键)的执行效率是最优的；如果表中只有一个字段，则select  count(*)最优。

阿里sql规范：

- 代码编写充分考虑执行速度最优的原则。
- 代码中需要添加必要的注释，以增强代码的可读性。
- 规范要求并非强制性约束开发人员的代码编写行为。实际应用中，在不违反常规要求的前提下，允许存在可以理解的偏差。
- SQL代码中应用到的所有SQL关键字、保留字都需使用全大写或小写，例如select/SELECT、from/FROM、where/WHERE、and/AND、or/OR、union/UNION、insert/INSERT、delete/DELETE、group/GROUP、having/HAVING和count/COUNT等。不能使用大小写混合的方式，例如Select或seLECT等方式。
- 4个空格为1个缩进量，所有的缩进均为1个缩进量的整数倍，按照代码层次对齐。
- 禁止使用select *操作，所有操作必须明确指定列名。
- 对应的括号要求在同一列的位置上。

## **Oracle**

以下因为我实习用的Oracle，所以基于oracle相关用法如下

```sql
-- merge into 范例
merge into STATIS T1 using dual on ((select count(*) from XXX where ID = '10001') > 0)
when matched then
	update set T1.AVERAGE = '20000' , T1.STD='2' , T1.INSERT_TIME = TO_DATE( TO_CHAR( SYSDATE, 'YYYY-MM-DD' ), 'YYYY-MM-DD HH24:MI:SS' ) WHERE CAMP_ID='10001'
when not matched then
	Insert (ID,AVERAGE, STD,INSERT_TIME) VALUES('10001','10000','0',TO_DATE( TO_CHAR( SYSDATE, 'YYYY-MM-DD' ), 'YYYY-MM-DD HH24:MI:SS' ));
	
-- CASE WHEN 范例
(
	CASE	
		WHEN T1.SEND_COUNT_TO_JYJ <= ( T2.AVERAGE + T2.STD ) 
			AND T1.SEND_COUNT_TO_JYJ >= ( T2.AVERAGE - T2.STD ) 
    	THEN
			'1' ELSE '2' 
	END 
) AS CAMP_TRUE_TYPE

-- UNION ALL 与 UNION区别也说一下吧，union all会去掉重复的数据

```

创建索引

## 创建索引

**单列索引：**

单列索引是基于单个列所建立的索引，比如：

create index 索引名 on 表名(列名);

**复合索引：**

复合索引是基于两列或是多列的索引。在同一张表上可以有多个索引，但是要求列的组合必须不同，比如：

create index emp_idx1 on emp (ename, job);

create index emp_idx1 on emp (job, ename);

查询表索引

select * from all_indexes where table_name = 'BMA_RT_CAMP_HOUR_SUM' 

## ShardingSphere进行分库分表

mysql数据量瓶颈大概在1kw，

- 垂直分表：将一张表字段分为多张表，每张表一部分字段

  - 可以分为热门字段与冷门字段，大字段一定要放冷门字段里
    - 原因：因为数据本身过长需要更多读取时间
    - mysql查找定位以页作为单位，页数据行越多整体性能越好，大字段占空间，IO效率低
    - 数据以行为单位进行加载，行数据越少，内存可以加载更多数据，减少磁盘IO，提升效率

- 垂直分库：垂直分表只解决单一表数据量大问题，每张表还是竞争同一个物理机CPU，内存，网络IO

  - 将表进行分类：分别部署于不同DB，每个库放不同服务器，微服务使用单独的数据库
    - 可以将业务解耦，分级管理，维护，监控，扩展
    - 高并发时，可以提升IO，减少数据库连接数，降低单机硬件资源瓶颈

- 水平分表：将表数据，按一定规则拆分到多个表，比如id哪一段，去哪个表

  - 可以优化单一表数据过大的性能问题

  - 避免IO争夺减少锁表几率

    分表方式：Hash取模，数据分片较为平均，不容易出现热点，并发访问瓶颈。（跨分片查询复杂问题）

    ​				按Range分表，id区间或时间区间分表，可以避免跨分片查询问题，但是热点数据可能会成为瓶颈

    ​				一致性Hash算法

- 水平分库：把表数据分到不同库，部署在不同服务器中，解决数据量，高并发瓶颈，但系统复杂度大

适用场景：

- 垂直分表：热点数据，冷门数据分开存，大字段冷门数据表里
- 垂直分库：按业务拆分，提升架构业务清晰度，解决单一服务器性能瓶颈
- 水平分表：解决单一表数据量过大
- 水平分库：把一张表数据分存到不同服务器，解决单一数据库数据量过大

不过分库分表后，也带来了一些问题

比如说：

**事务怎么办**

解决方案：

1. 分布式事务：数据库来管理，但性能代价高
2. 由应用程序与DB控制，把大的分布式事务拆分为单个DB的小事务。（性能更好，但是需要改动Spring事务管理机制）

**跨节点查询join**问题：分两次查询

主键ID：UUID,维护一个Sequence表，SnowFlake雪花ID

**分库数量**：分库数量首先和单库处理能力息息相关，比如MySQL单库超过5000万记录，Oracle单库超过1亿条记录，数据库压力就很大了。（4~8）

#### 第三方解决方案	ShardingSphere

Apache ShardingSphere是一套来源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）这三款相互独立，却又能够混合部署配合使用的产品组成。它们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。

ShardingShpere定位为关系型数据库中间件，旨在充分合理地在分布式场景下利用关系型数据库的计算和存储能力，而并非实现一个全新的关系型数据库。

1、连接
通过对数据库协议、SQL方言以及数据库存储的灵活适配，快速的连接应用与多模式的异构数据库。

2、增量
获取数据库的访问流量，并提供流量重定向（数据分片、读写分离、影子库）、流量变形（数据加密、数据脱敏）、流量鉴权（安全、审计、权限）、流量治理（熔断、限流）以及流量分析（服务质量分析、可观察性）等透明化增量功能。

3、可插拔
项目采用微内核 + 3层可插拔模式，使内核、功能组件以及生态对接完全能够灵活的方式进行可插拔式扩展，开发者能够像使用积木一样定制数据自己的独特系统。
后面还有其三种产品………………

https://blog.csdn.net/CXY_QIQI/article/details/124822976

## 关于Explain

范例：

![image-20221104111100922](E:\IDEA\Docs\文档\photo\image-20221104111100922.png)

字段描述

- id:

mysql:explain 官方文档https://dev.mysql.com/doc/refman/8.0/en/explain-output.html
